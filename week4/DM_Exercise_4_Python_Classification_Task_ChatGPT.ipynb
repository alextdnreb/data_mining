{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below if you are using Google Colab to mount your Google Drive in your Colab instance. Adjust the path to the files in your Google Drive as needed if it differs.\n",
    "\n",
    "If you do not use Google Colab, running the cell will simply do nothing, so do not worry about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    %cd 'drive/My Drive/Colab Notebooks/04_Classification'\n",
    "except ImportError as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 4: Classification\n",
    "\n",
    "### 4.1. Learning a classifier for the Iris Data Set – Part II\n",
    "\n",
    "In the last exercise, you have learned classification models for the Iris dataset using a train/test split. Now try learning a decision tree and evaluate it with 10-fold cross-validation. Use a pipeline to perform some preprocessing before learning or applying the decision tree classifier. For this exercise, we use the ```iris_imbalanced.csv``` dataset, so it's a good idea to include a balancing step in the preprocessing!\n",
    "\n",
    "#### 4.1.1.\tDiscretise the Iris data set into three bins. Then use the DecisionTreeClassifier with a 10-fold stratified cross validation and compute the accuracy. Afterwards plot the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "## Windows users: either add the path to graphviz' dot.exe to your PATH variable \n",
    "## OR comment in the 2 lines below (may have to change path):\n",
    "\n",
    "# import os\n",
    "# os.environ['PATH'] += ';C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin'\n",
    "\n",
    "# load the dataset\n",
    "iris = pd.read_csv(\"iris_imbalanced.csv\")\n",
    "iris_data = iris[['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']]\n",
    "iris_target = iris['Name']\n",
    "\n",
    "# define a pipeline including a discretiser, balancing, and a decision tree classifier\n",
    "#TODO: INSERT YOUR CODE HERE!\n",
    "\n",
    "# evaluate the pipeline\n",
    "accuracy = cross_val_score(pipeline, iris_data, iris_target, cv=10, scoring='accuracy')\n",
    "\n",
    "# fit the pipeline to the dataset \n",
    "pipeline.fit(iris_data, iris_target)\n",
    "\n",
    "print(\"Fitted a decision tree with {} nodes. Cross-validated accuracy is {}%\".format(estimator.tree_.node_count, accuracy.mean() * 100))\n",
    "\n",
    "# plot the decision tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "tree.plot_tree(estimator,\n",
    "               feature_names=iris_data.columns, \n",
    "               class_names=iris_target.unique())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 4.1.2.\tRemove the discretization and adjust the max_depth parameter of DecisionTreeClassifier to increase the accuracy. Does the accuracy change? Compare the complexity of the two models. Which model should be preferred according to Occam’s razor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable the discretiser\n",
    "#TODO: INSERT YOUR CODE HERE!\n",
    "\n",
    "# re-evaluate the pipeline\n",
    "accuracy = cross_val_score(pipeline, iris_data, iris_target, cv=10, scoring='accuracy')\n",
    "\n",
    "# fit the pipeline to the dataset again\n",
    "pipeline.fit(iris_data, iris_target)\n",
    "\n",
    "print(\"Fitted a decision tree with {} nodes. Cross-validated accuracy is {}%\".format(estimator.tree_.node_count, accuracy.mean() * 100))\n",
    "\n",
    "# plot the decision tree\n",
    "plt.figure(figsize=(20,15))\n",
    "tree.plot_tree(estimator,\n",
    "               feature_names=iris_data.columns, \n",
    "               class_names=iris_target.unique())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# adjust the max_depth parameter and re-evaluate\n",
    "for depth in range(1, 9):\n",
    "    #TODO: INSERT YOUR CODE HERE!\n",
    "    \n",
    "    accuracy = cross_val_score(pipeline, iris_data, iris_target, cv=10, scoring='accuracy')\n",
    "    print(\"max_depth={}: {}% accuracy\".format(depth, accuracy.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# choose a good parameter setting and re-fit the pipeline to the dataset\n",
    "#TODO: INSERT YOUR CODE HERE!\n",
    "\n",
    "\n",
    "pipeline.fit(iris_data, iris_target)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "tree.plot_tree(estimator,\n",
    "               feature_names=iris_data.columns, \n",
    "               class_names=iris_target.unique())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Which model would you choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.2. Who should get a bank credit?\n",
    "The German credit data set from the UCI data set library (http://archive.ics.uci.edu/ml/index.html) describes the customers of a bank with respect to whether they should get a bank credit or not. The data set is provided as credit-g.arff file in ILIAS. \n",
    "\n",
    "#### 4.2.1. Plot ROC curves for k-NN (different k values) and Decision Tree (you can use the given avg_roc function) . Which classification approach looks most promising to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_status</th>\n",
       "      <th>employment</th>\n",
       "      <th>installment_commitment</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>other_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>property_magnitude</th>\n",
       "      <th>age</th>\n",
       "      <th>other_payment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>own_telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>critical/other existing credit</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>no known savings</td>\n",
       "      <td>&gt;=7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>67.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0&lt;=X&lt;200</td>\n",
       "      <td>48.0</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>1&lt;=X&lt;4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female div/dep/mar</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>22.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no checking</td>\n",
       "      <td>12.0</td>\n",
       "      <td>critical/other existing credit</td>\n",
       "      <td>education</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>4&lt;=X&lt;7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>49.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unskilled resident</td>\n",
       "      <td>2.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>4&lt;=X&lt;7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>guarantor</td>\n",
       "      <td>...</td>\n",
       "      <td>life insurance</td>\n",
       "      <td>45.0</td>\n",
       "      <td>none</td>\n",
       "      <td>for free</td>\n",
       "      <td>1.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>delayed previously</td>\n",
       "      <td>new car</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>1&lt;=X&lt;4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>no known property</td>\n",
       "      <td>53.0</td>\n",
       "      <td>none</td>\n",
       "      <td>for free</td>\n",
       "      <td>2.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  checking_status  duration                  credit_history  \\\n",
       "0              <0       6.0  critical/other existing credit   \n",
       "1        0<=X<200      48.0                   existing paid   \n",
       "2     no checking      12.0  critical/other existing credit   \n",
       "3              <0      42.0                   existing paid   \n",
       "4              <0      24.0              delayed previously   \n",
       "\n",
       "               purpose  credit_amount    savings_status employment  \\\n",
       "0             radio/tv         1169.0  no known savings        >=7   \n",
       "1             radio/tv         5951.0              <100     1<=X<4   \n",
       "2            education         2096.0              <100     4<=X<7   \n",
       "3  furniture/equipment         7882.0              <100     4<=X<7   \n",
       "4              new car         4870.0              <100     1<=X<4   \n",
       "\n",
       "   installment_commitment     personal_status other_parties  ...  \\\n",
       "0                     4.0         male single          none  ...   \n",
       "1                     2.0  female div/dep/mar          none  ...   \n",
       "2                     2.0         male single          none  ...   \n",
       "3                     2.0         male single     guarantor  ...   \n",
       "4                     3.0         male single          none  ...   \n",
       "\n",
       "   property_magnitude   age  other_payment_plans   housing existing_credits  \\\n",
       "0         real estate  67.0                 none       own              2.0   \n",
       "1         real estate  22.0                 none       own              1.0   \n",
       "2         real estate  49.0                 none       own              1.0   \n",
       "3      life insurance  45.0                 none  for free              1.0   \n",
       "4   no known property  53.0                 none  for free              2.0   \n",
       "\n",
       "                  job num_dependents  own_telephone foreign_worker class  \n",
       "0             skilled            1.0            yes            yes  good  \n",
       "1             skilled            1.0           none            yes   bad  \n",
       "2  unskilled resident            2.0           none            yes  good  \n",
       "3             skilled            2.0           none            yes  good  \n",
       "4             skilled            2.0           none            yes   bad  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "\n",
    "credit_arff_data, credit_arff_meta = arff.loadarff(open('credit-g.arff', 'r'))\n",
    "credit = pd.DataFrame(credit_arff_data)\n",
    "# select all columns of type object\n",
    "columns_with_binary_strings = credit.select_dtypes('object').columns.values\n",
    "\n",
    "# decode the values of these columns using utf-8\n",
    "credit[columns_with_binary_strings] = credit[columns_with_binary_strings].apply(lambda x: x.str.decode(\"utf-8\"))\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First define the preprocessing. Have a look at the class distribution and feature types and think about appropriate transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# separate the target variable from the features\n",
    "credit_target = credit['class']\n",
    "credit_data = credit.drop('class', axis=1)\n",
    "\n",
    "# plot the class distribution\n",
    "#TODO: INSERT YOUR CODE HERE!\n",
    "amounts = pd.Series(credit_target).value_counts()\n",
    "plt.bar(amounts.index, amounts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.23647786,  0.91847717,  2.76645648, ...,  4.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 2.24819436, -0.87018333, -1.19140394, ...,  2.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.73866754, -0.87018333,  1.18331231, ...,  2.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [-0.73866754,  0.91847717,  0.21583532, ...,  2.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.9992892 ,  0.91847717, -1.10345149, ...,  2.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 1.9992892 ,  0.02414692, -0.75164167, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_features = [\"duration\", \"installment_commitment\", \"age\", \"credit_amount\", \"existing_credits\", \"num_dependents\"]\n",
    "numeric_encoder = Pipeline([ ('scaler', StandardScaler()) ])\n",
    "\n",
    "categorical_features = [\"credit_history\", \"purpose\", \"personal_status\", \"other_parties\", \"property_magnitude\", \"other_payment_plans\", \"housing\", \"job\"]\n",
    "categorical_encoder = Pipeline([ ('onehot', OneHotEncoder()) ])\n",
    "\n",
    "ordinal_features = [\"employment\", \"checking_status\", \"savings_status\", \"own_telephone\", \"foreign_worker\"]\n",
    "ordinal_encoder = Pipeline([ ('ordinal', OrdinalEncoder()) ])\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_encoder, numeric_features),\n",
    "        ('cat', categorical_encoder, categorical_features),\n",
    "        ('ord', ordinal_encoder, ordinal_features)])\n",
    "# think about which features you want to re-scale, encode using one-hot encoding or encode using ordinal encoding\n",
    "# then, create a ColumnTransformer to execute this preprocessing for you\n",
    "\n",
    "display(transformer.fit_transform(credit_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell once to define the ```avg_roc``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#define function for computing average roc for cross validation\n",
    "#see http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def avg_roc(cv, estimator, data, target, pos_label):\n",
    "    mean_fpr = np.linspace(0, 1, 100) # = [0.0, 0.01, 0.02, 0.03, ... , 0.99, 1.0]\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    \n",
    "    for train_indices, test_indices in cv.split(data, target):\n",
    "        train_data = data.iloc[train_indices]\n",
    "        train_target = target[train_indices]\n",
    "        estimator.fit(train_data, train_target)\n",
    "\n",
    "        test_data = data.iloc[test_indices]\n",
    "        test_target = target[test_indices]\n",
    "        decision_for_each_class = estimator.predict_proba(test_data)#have to use predict_proba or decision_function \n",
    "    \n",
    "        fpr, tpr, thresholds = roc_curve(test_target, decision_for_each_class[:,1], pos_label=pos_label)\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0 # tprs[-1] access the last element\n",
    "        aucs.append(auc(fpr, tpr))\n",
    "        \n",
    "        #plt.plot(fpr, tpr)# plot for each fold\n",
    "        \n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0 # set the last tpr to 1\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "    return mean_fpr, mean_tpr, mean_auc, std_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluate different classifiers using the ```avg_roc``` function and plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# define the cross validation folds\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# create the pipeline, we will set the estimator later\n",
    "pipeline = Pipeline([ ('preprocessing', preprocessor), ('estimator', None) ])\n",
    "\n",
    "# setup a figure\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Random', alpha=.8) # draw diagonal\n",
    "\n",
    "# KNN\n",
    "#TODO: INSERT YOUR CODE HERE!\n",
    "pipeline.set_params(estimator=KNeighborsClassifier())\n",
    "for n_neighbour in [2,3,4,5,6]:\n",
    "    pipeline.set_params(estimator__n_neighbors=n_neighbour)\n",
    "    mean_fpr, mean_tpr, mean_auc, std_auc = avg_roc(cv, pipeline, credit_data, credit_target, 'good')\n",
    "    plt.plot(mean_fpr, mean_tpr, label='{}-NN (AUC: {:.3f} $\\pm$ {:.3f})'.format(n_neighbour, mean_auc, std_auc))\n",
    "    \n",
    "# Decision Tree\n",
    "#TODO: INSERT YOUR CODE HERE!\n",
    "mean_fpr, mean_tpr, mean_auc, std_auc = avg_roc(cv, pipeline, credit_data, credit_target, 'good')\n",
    "plt.plot(mean_fpr, mean_tpr, label='DecisonTree (AUC: {:.3f} $\\pm$ {:.3f})'.format(mean_auc, std_auc))\n",
    "\n",
    "# show the plot\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 4.2.2.\tFor the two most promising classification approaches, compute the accuracy and confusion matrix in a 10-fold CV setup. Which level of accuracy do you reach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Plot confusion matrix and classification report for the two most promising approaches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 4.2.3.\tWhat do the precision and recall values for the class “bad”  tell you? Try to improve the situation by increasing the number of “bad” examples in the training set (in the cross validation). How do precision and recall change if you apply this procedure? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# upsample the \"bad\" examples and evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 4.2.4.\tTo model a use case specific evaluation, compute the cost of all missclassifications. Set up your cost matrix by assuming that you will lose 1 Unit if you refuse a credit to a good customer, but that you lose 100 Units if you give a bad customer a credit. Rerun the experiments and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# create the predictions here\n",
    "# prediction = ...\n",
    "\n",
    "# You can use the following code to calculate the cost\n",
    "cm = confusion_matrix(credit_target, prediction, labels=credit_target.unique())\n",
    "cost = cm[0][1] * 100 + cm[1][0] * 1\n",
    "acc = accuracy_score(credit_target, prediction)\n",
    "print(\"6-NN with accuracy of {} and cost {}\".format(acc, cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 4.2.5.\tAs the creation of training data is mostly a manual task and humans tend to be fallible, training data might include noise. Simulate this behavior by using the Add Noise function and change the parameter “percentage” from 0% over 10% to 20%. Is your preferred classification approach still feasible for this situation? How does the performance of the other classifiers evolve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import random \n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "def add_noise(raw_target, percentage):    \n",
    "    labels = unique_labels(raw_target)\n",
    "    target_with_noise = []\n",
    "    for one_target_label in raw_target:\n",
    "        if random.randint(1,100) <= percentage:\n",
    "            target_with_noise.append(next(l for l in labels if l != one_target_label))\n",
    "        else:\n",
    "            target_with_noise.append(one_target_label)\n",
    "    return target_with_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add noise to your training splits and evaluate (e.g. use manual cross validation (see intro slides) for this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT Bonus Exercises\n",
    "Reminder: Do not take the answers of ChatGPT at face value! Always cross-check with lecture slides, literature and/or the teaching staff!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.1. Discuss Evaluation Setups/Metrics\n",
    "* Use ChatGPT to discuss the various evaluation setups you learned about. What would be reasons to choose holdout validation over cross-validation? What are the pitfalls you should look out for when doing any kind of dataset splitting for evaluation and how can you avoid them?\n",
    "* You want to use k-fold cross-validation for model evaluation. Discuss with ChatGPT what a good value for k is and what factors would influence the optimal choice of k. What problem could you run into when setting k too high?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.2. Learn about more ways for handling class imbalance in Python\n",
    "* Ask ChatGPT about more sophisticated methods for handling class imbalance available in the imbalanced learn package and have it explain them to you. Finally, let ChatGPT generate some code for an advanced method and apply it to the credit data set from exercise 4.2. and compare to the results you achieved with simple over-/undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ask ChatGPT about additional methods for handling class imbalance that are not based on changing the data distribution in the training set. Select a promising method, let ChatGPT generate code for it and use it to compare to your previous results on the credit data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.3. Self-Assessment\n",
    "* Ask ChatGPT to create a pen and paper exercise for you that lets you practice the calculation of the evaluation metrics Precision, Recall and F1. Instruct ChatGPT to provide a confusion matrix for three classes and subsequently calculate the measure for each class.\n",
    "* Ask ChatGPT to create an exam exercise for graduate students relating to the effect of overfitting in Decision Tree classifiers and solve the exercise. Get the answer from ChatGPT and critically evaluate it.\n",
    "* Ask ChatGPT to create three multiple choice questions for graduate students about choosing the best evaluation metrics for example classification tasks and solve them."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
